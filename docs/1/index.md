# 线性回归与逻辑回归

### 线性回归

#### 模型公式：

$$y' = b + w_1 x_1$$

-  $b$是**偏差**模型。偏差与截距的概念相同。在机器学习中，偏差有时称为 ${w_0}$。
-  ${w_1}$是**权重**功能。权重与斜率的概念相同。
-  权重与偏差都是在训练中计算的。



#### 损失

损失是一个数值指标，损失函数用于衡量模型预测效果精准度。

训练模型的目标是尽可能降低损失，将其降至最低值。

![损失函数](/image/1_1.png)

### 丢失距离

损失函数侧重于值之间的距离。

有两种常用方法。

* 计算预测值与实际值的绝对值。
* 将预测值与实际值误差平方。



### 损失类型

四种主要损失函数如下所示

| 损失类型            | 定义                             | 公式            |
| ------------------- | -------------------------------- | -------------------------------- |
| L1损失            | 预测值与实际值差值的绝对值的总和 | $$\sum{|{y_i}-{y_i'}|}$$        |
| MAE（平均绝对误差） | 一组L1损失的平均值             | $$\frac{1}{N}\sum{|{y_i}-{y_i'}|}$$    |
| L2损失            | 预测值与实际值之间平方差的总和   | $$\sum{({y_i}-{y_i'})^2}$$             |
| MSE（均方误差）     | 一组L2的损失平均值             | $$\frac{1}{N}\sum{({y_i}-{y_i'})^2}$$       |

当预测值与标签之间的差异较大时，平方会使得损失变得更大，当差值很小（小于1）时候则会让损失更小。



### 逻辑回归

如果说线性回归可用于预测某些数值型数据，那么逻辑回归则旨在预测给定结果的概率。

例如预测今天会下雨的概率是多少。



####  模型公式

$$z = b + {w_1}{x_1} + {w_2}{x_2} + ... + {w_n}{x_n}$$

其中

- *z* 是线性方程的输出

- *b* 是偏差。

- w 的值是模型学习的权重。

- x 的值是特定样本的特征值。

要获得逻辑回归预测结果，将z值传递给**sigmoid**函数，得到介于0和1的概率。

$$f'(x) = \dfrac{1}{1+e^{-x}}$$



![sigmoid函数](/image/1_2.png)



逻辑回归模型训练过程和线性回归的关键区别：

* 逻辑回归模型使用**对数损失函数**作为损失函数而不是**平方损失函数（L2）**。
* 应用正则化为了防止过拟合。



#### 对数损失函数

公式如下：

$$LogLoss = \sum_{(x,y) \in D} - {y}{log(y')-{(1-y)}{log(1-y')}}$$

其中：

- $(x,y) \in D$ 是包含多个有标签样本的数据集。
- $y$ 是有标签样本中的标签。
- $y'$ 是模型的预测结果（介于 0 和 1 之间）



#### 正则化

正则化目的是降低模型复杂度。大部分逻辑回归模型都需要进行正则化来降低复杂度。

* L2正则化
* 限制训练步数
